{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:29:37.247308Z","iopub.execute_input":"2025-07-08T11:29:37.247569Z","iopub.status.idle":"2025-07-08T11:29:37.620355Z","shell.execute_reply.started":"2025-07-08T11:29:37.247544Z","shell.execute_reply":"2025-07-08T11:29:37.619393Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import nltk \nnltk.download('gutenberg')\nfrom nltk.corpus import gutenberg\nimport pandas as pd\n\ndata = gutenberg.raw('shakespeare-hamlet.txt')\nemma_text = gutenberg.raw('austen-emma.txt')\nmoby_dick = gutenberg.raw('melville-moby_dick.txt')\n##save to file\n\nwith open('hamlet.txt', 'w', encoding='utf-8') as f:\n    f.write(data)\n\nwith open('emma.txt', 'w', encoding='utf-8') as f:\n    f.write(emma_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:29:37.622361Z","iopub.execute_input":"2025-07-08T11:29:37.622982Z","iopub.status.idle":"2025-07-08T11:29:38.441916Z","shell.execute_reply.started":"2025-07-08T11:29:37.622959Z","shell.execute_reply":"2025-07-08T11:29:38.441137Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package gutenberg to /usr/share/nltk_data...\n[nltk_data]   Package gutenberg is already up-to-date!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"with open('combined_dataset.txt', 'w', encoding='utf-8') as f:\n    f.write(data + '\\n' + emma_text + '\\n' + moby_dick)\n\nprint(\"✅ All texts saved! You can now train on 'combined_dataset.txt'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:30:30.640468Z","iopub.execute_input":"2025-07-08T11:30:30.641074Z","iopub.status.idle":"2025-07-08T11:30:30.652050Z","shell.execute_reply.started":"2025-07-08T11:30:30.641051Z","shell.execute_reply":"2025-07-08T11:30:30.651228Z"}},"outputs":[{"name":"stdout","text":"✅ All texts saved! You can now train on 'combined_dataset.txt'\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"## Data Preprocessing\nimport numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\n\n##load The Dataset\nwith open('/kaggle/working/combined_dataset.txt','r') as file:\n    text = file.read().lower()\n\nwords = text.split()\nlimited_text = ' '.join(words[:100000])  # first 100,000 words only\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts([text])\ntotal_words = len(tokenizer.word_index)+1\ntotal_words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:30:44.750356Z","iopub.execute_input":"2025-07-08T11:30:44.750717Z","iopub.status.idle":"2025-07-08T11:30:44.998853Z","shell.execute_reply.started":"2025-07-08T11:30:44.750692Z","shell.execute_reply":"2025-07-08T11:30:44.998223Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"22711"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"input_sequences = []\nmax_seq_len = 20\nmax_total_sequences = 50000  # Optional: limit to prevent RAM crash\n\nfor line in limited_text.split('\\n'):\n    token_list = tokenizer.texts_to_sequences([line])[0]\n\n    # Skip very short lines\n    if len(token_list) < 2:\n        continue\n\n    # Slide through the token list with a step of 1 or 20 (you can adjust this)\n    for i in range(1, len(token_list)):\n        n_gram_seq = token_list[:i+1]\n\n        # Break long sequences into chunks of 20\n        if len(n_gram_seq) > max_seq_len:\n            for j in range(max_seq_len, len(n_gram_seq) + 1, max_seq_len):\n                chunk = n_gram_seq[j - max_seq_len:j]\n                input_sequences.append(chunk)\n        else:\n            input_sequences.append(n_gram_seq)\n\n        if len(input_sequences) >= max_total_sequences:\n            break\n\n    if len(input_sequences) >= max_total_sequences:\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:30:49.350603Z","iopub.execute_input":"2025-07-08T11:30:49.351200Z","iopub.status.idle":"2025-07-08T11:30:49.408461Z","shell.execute_reply.started":"2025-07-08T11:30:49.351181Z","shell.execute_reply":"2025-07-08T11:30:49.407810Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"input_sequences[0:20]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:30:59.290716Z","iopub.execute_input":"2025-07-08T11:30:59.291245Z","iopub.status.idle":"2025-07-08T11:30:59.298045Z","shell.execute_reply.started":"2025-07-08T11:30:59.291212Z","shell.execute_reply":"2025-07-08T11:30:59.297235Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[[1, 6133],\n [1, 6133, 3],\n [1, 6133, 3, 398],\n [1, 6133, 3, 398, 30],\n [1, 6133, 3, 398, 30, 1407],\n [1, 6133, 3, 398, 30, 1407, 9334],\n [1, 6133, 3, 398, 30, 1407, 9334, 12829],\n [1, 6133, 3, 398, 30, 1407, 9334, 12829, 9335],\n [1, 6133, 3, 398, 30, 1407, 9334, 12829, 9335, 12830],\n [1, 6133, 3, 398, 30, 1407, 9334, 12829, 9335, 12830, 12831],\n [1, 6133, 3, 398, 30, 1407, 9334, 12829, 9335, 12830, 12831, 12832],\n [1, 6133, 3, 398, 30, 1407, 9334, 12829, 9335, 12830, 12831, 12832, 386],\n [1,\n  6133,\n  3,\n  398,\n  30,\n  1407,\n  9334,\n  12829,\n  9335,\n  12830,\n  12831,\n  12832,\n  386,\n  3760],\n [1,\n  6133,\n  3,\n  398,\n  30,\n  1407,\n  9334,\n  12829,\n  9335,\n  12830,\n  12831,\n  12832,\n  386,\n  3760,\n  2],\n [1,\n  6133,\n  3,\n  398,\n  30,\n  1407,\n  9334,\n  12829,\n  9335,\n  12830,\n  12831,\n  12832,\n  386,\n  3760,\n  2,\n  9336],\n [1,\n  6133,\n  3,\n  398,\n  30,\n  1407,\n  9334,\n  12829,\n  9335,\n  12830,\n  12831,\n  12832,\n  386,\n  3760,\n  2,\n  9336,\n  110],\n [1,\n  6133,\n  3,\n  398,\n  30,\n  1407,\n  9334,\n  12829,\n  9335,\n  12830,\n  12831,\n  12832,\n  386,\n  3760,\n  2,\n  9336,\n  110,\n  12833],\n [1,\n  6133,\n  3,\n  398,\n  30,\n  1407,\n  9334,\n  12829,\n  9335,\n  12830,\n  12831,\n  12832,\n  386,\n  3760,\n  2,\n  9336,\n  110,\n  12833,\n  3760],\n [1,\n  6133,\n  3,\n  398,\n  30,\n  1407,\n  9334,\n  12829,\n  9335,\n  12830,\n  12831,\n  12832,\n  386,\n  3760,\n  2,\n  9336,\n  110,\n  12833,\n  3760,\n  2081],\n [1,\n  6133,\n  3,\n  398,\n  30,\n  1407,\n  9334,\n  12829,\n  9335,\n  12830,\n  12831,\n  12832,\n  386,\n  3760,\n  2,\n  9336,\n  110,\n  12833,\n  3760,\n  2081]]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"## padding the sequences\nmax_sequence_length = max([len(x) for x in input_sequences])\nmax_sequence_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:31:05.991266Z","iopub.execute_input":"2025-07-08T11:31:05.991583Z","iopub.status.idle":"2025-07-08T11:31:05.999351Z","shell.execute_reply.started":"2025-07-08T11:31:05.991560Z","shell.execute_reply":"2025-07-08T11:31:05.998543Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"input_sequences = np.array(pad_sequences(input_sequences,maxlen = max_sequence_length,padding = 'pre'))\ninput_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:31:11.322216Z","iopub.execute_input":"2025-07-08T11:31:11.322552Z","iopub.status.idle":"2025-07-08T11:31:11.458376Z","shell.execute_reply.started":"2025-07-08T11:31:11.322529Z","shell.execute_reply":"2025-07-08T11:31:11.457674Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([[    0,     0,     0, ...,     0,     1,  6133],\n       [    0,     0,     0, ...,     1,  6133,     3],\n       [    0,     0,     0, ...,  6133,     3,   398],\n       ...,\n       [  127,   984,  1135, ...,    20,    38, 12930],\n       [    2,    38,  1877, ...,   920,     2, 12932],\n       [  369,     4,   409, ...,  7365,   353,    19]], dtype=int32)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"##creating input and label\n\nimport tensorflow as tf\nx,y = input_sequences[:,:-1],input_sequences[:,-1]\n\ny","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:31:16.471386Z","iopub.execute_input":"2025-07-08T11:31:16.472075Z","iopub.status.idle":"2025-07-08T11:31:16.480002Z","shell.execute_reply.started":"2025-07-08T11:31:16.472036Z","shell.execute_reply":"2025-07-08T11:31:16.478927Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([ 6133,     3,   398, ..., 12930, 12932,    19], dtype=int32)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"y = tf.keras.utils.to_categorical(y,num_classes = total_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:31:19.970039Z","iopub.execute_input":"2025-07-08T11:31:19.970633Z","iopub.status.idle":"2025-07-08T11:31:20.125254Z","shell.execute_reply.started":"2025-07-08T11:31:19.970608Z","shell.execute_reply":"2025-07-08T11:31:20.124368Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:31:22.725465Z","iopub.execute_input":"2025-07-08T11:31:22.726218Z","iopub.status.idle":"2025-07-08T11:31:28.102310Z","shell.execute_reply.started":"2025-07-08T11:31:22.726191Z","shell.execute_reply":"2025-07-08T11:31:28.101515Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n#Define the model\nmodel=Sequential()\nmodel.add(Embedding(total_words,100,input_length = max_sequence_length))\nmodel.add(LSTM(128,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(128))\nmodel.add(Dense(total_words,activation=\"softmax\"))\n\n##compiling\nmodel.build(input_shape=(None, max_sequence_length))\nmodel.compile(loss = \"categorical_crossentropy\",optimizer = \"adam\",metrics = ['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:34:50.170916Z","iopub.execute_input":"2025-07-08T11:34:50.171640Z","iopub.status.idle":"2025-07-08T11:34:50.244850Z","shell.execute_reply.started":"2025-07-08T11:34:50.171605Z","shell.execute_reply":"2025-07-08T11:34:50.244135Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:34:53.119847Z","iopub.execute_input":"2025-07-08T11:34:53.120352Z","iopub.status.idle":"2025-07-08T11:34:53.135275Z","shell.execute_reply.started":"2025-07-08T11:34:53.120324Z","shell.execute_reply":"2025-07-08T11:34:53.134697Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m2,271,100\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m117,248\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22711\u001b[0m)          │     \u001b[38;5;34m2,929,719\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,271,100</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22711</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,929,719</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,449,651\u001b[0m (20.79 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,449,651</span> (20.79 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,449,651\u001b[0m (20.79 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,449,651</span> (20.79 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"##training\nhistory = model.fit(x_train,y_train,epochs = 10,validation_data = (x_test,y_test),verbose = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:34:59.870832Z","iopub.execute_input":"2025-07-08T11:34:59.871315Z","iopub.status.idle":"2025-07-08T11:38:21.524258Z","shell.execute_reply.started":"2025-07-08T11:34:59.871290Z","shell.execute_reply":"2025-07-08T11:38:21.523619Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - accuracy: 0.0746 - loss: 4.4032 - val_accuracy: 0.0770 - val_loss: 3.8128\nEpoch 2/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.0953 - loss: 3.7013 - val_accuracy: 0.7970 - val_loss: 1.0833\nEpoch 3/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.8846 - loss: 0.6756 - val_accuracy: 0.9797 - val_loss: 0.1483\nEpoch 4/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.9839 - loss: 0.1184 - val_accuracy: 0.9997 - val_loss: 0.0423\nEpoch 5/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 0.0341 - val_accuracy: 0.9997 - val_loss: 0.0146\nEpoch 6/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.9996 - loss: 0.0123 - val_accuracy: 0.9997 - val_loss: 0.0076\nEpoch 7/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.9996 - loss: 0.0066 - val_accuracy: 0.9997 - val_loss: 0.0064\nEpoch 8/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.9996 - loss: 0.0044 - val_accuracy: 0.9999 - val_loss: 0.0029\nEpoch 9/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.9999 - val_loss: 0.0022\nEpoch 10/10\n\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 0.0020\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ndef predict_next_word(model, tokenizer, text, max_sequence_length):\n    # Convert input text to token list\n    token_list = tokenizer.texts_to_sequences([text])[0]\n\n    # Ensure the token list is of the correct length\n    if len(token_list) >= max_sequence_length:\n        token_list = token_list[-(max_sequence_length - 1):]  # leave space for next word\n\n    # Pad the sequence\n    token_list = pad_sequences([token_list], maxlen=max_sequence_length, padding='pre')\n\n    # Predict the next word\n    predicted_probs = model.predict(token_list, verbose=0)\n    predicted_word_index = np.argmax(predicted_probs, axis=1)[0]  # Get scalar from array\n\n    # Map index back to word\n    for word, index in tokenizer.word_index.items():\n        if index == predicted_word_index:\n            return word\n\n    return None  # In case the word wasn't found\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:39:28.786587Z","iopub.execute_input":"2025-07-08T11:39:28.787223Z","iopub.status.idle":"2025-07-08T11:39:28.793058Z","shell.execute_reply.started":"2025-07-08T11:39:28.787199Z","shell.execute_reply":"2025-07-08T11:39:28.792188Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"input_text = \"To be or not to be\"\nprint(f\"Input_text :{input_text}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:40:05.751549Z","iopub.execute_input":"2025-07-08T11:40:05.752367Z","iopub.status.idle":"2025-07-08T11:40:05.757357Z","shell.execute_reply.started":"2025-07-08T11:40:05.752330Z","shell.execute_reply":"2025-07-08T11:40:05.756310Z"}},"outputs":[{"name":"stdout","text":"Input_text :To be or not to be\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"max_sequence_len = model.input_shape[1]\nnext_word = predict_next_word(model,tokenizer,input_text,max_sequence_len)\nprint(f\"next word prediction :{next_word}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:40:07.400064Z","iopub.execute_input":"2025-07-08T11:40:07.400619Z","iopub.status.idle":"2025-07-08T11:40:07.698525Z","shell.execute_reply.started":"2025-07-08T11:40:07.400590Z","shell.execute_reply":"2025-07-08T11:40:07.697774Z"}},"outputs":[{"name":"stdout","text":"next word prediction :clad\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"model.save(\"next_word_lstm.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:40:11.670234Z","iopub.execute_input":"2025-07-08T11:40:11.670791Z","iopub.status.idle":"2025-07-08T11:40:11.903897Z","shell.execute_reply.started":"2025-07-08T11:40:11.670766Z","shell.execute_reply":"2025-07-08T11:40:11.903069Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"##save the tokenizer\nimport pickle\nwith open('tokenizer.pickle','wb') as handle:\n pickle.dump(tokenizer,handle,protocol = pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T11:40:14.115379Z","iopub.execute_input":"2025-07-08T11:40:14.115695Z","iopub.status.idle":"2025-07-08T11:40:14.140883Z","shell.execute_reply.started":"2025-07-08T11:40:14.115669Z","shell.execute_reply":"2025-07-08T11:40:14.140287Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null}]}